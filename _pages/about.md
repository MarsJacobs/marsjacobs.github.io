---
layout: about
title: about
permalink: /
subtitle: Hanyang University. Seoul, South Korea. minsoo2333@hanyang.ac.kr

profile:
  align: right
  image: mskim_230127_idcard.jpg
  image_circular: false # crops the image to make it circular
  
news: false  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: false  # includes social icons at the bottom of the page
---

Hi! I am Minsoo Kim, I'm currently in my fourth year of the integrated Ph.D. program in the Artificial Intelligence Hardware & Algorithm lab at [Hanyang University](https://www.hanyang.ac.kr/web/eng). I am fortunate to be advised by professor [Jungwook Choi](https://jchoi-hyu.github.io/). Recently, I had the honor of being selected as a winner in the [Qualcomm Innovation Fellowship Korea 2023](https://www.qualcomm.com/research/university-relations/innovation-fellowship/2023-south-korea).

My core research focuses on understanding the effects of Quantization in language models across diverse NLP tasks aimed for efficient inference. Currently, my research interest lies in the area of memory-efficient LLM Fine-Tuning with Quantization. 

Not limited to Quantization, I also hold a deep interest in techniques for fine-tuning LLMs to unleash the potential of specialized LLMs, in the direction of democratizing LLMs for broader accessibility.

***I am actively looking for an internship in 2024.** If you are interested, please feel free to email me!*